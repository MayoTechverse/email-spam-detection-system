# -*- coding: utf-8 -*-
"""correct Task1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bxsWUz1IEYS8KNoxQEB-nd26aVgYSlIr
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import nltk
import string

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.preprocessing import LabelEncoder

# Download NLTK resources
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

# Load dataset
df = pd.read_csv('spam_assassin.csv')  # Ensure this CSV is in your working directory
df.dropna(inplace=True)

# Features and labels
X = df['text']
y = df['target']

# === Logistic Regression ===
print("\n=== Logistic Regression ===")
tfidf = TfidfVectorizer(min_df=5, ngram_range=(1, 3), stop_words='english')
X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train_tfidf = tfidf.fit_transform(X_train_tfidf)
X_test_tfidf = tfidf.transform(X_test_tfidf)

log_model = LogisticRegression(max_iter=1000, solver='liblinear', random_state=0)
log_model.fit(X_train_tfidf, y_train)
y_pred_log = log_model.predict(X_test_tfidf)
log_probs = log_model.predict_proba(X_test_tfidf)[:, 1]

# Evaluation
print(f"Accuracy: {accuracy_score(y_test, y_pred_log):.4f}")
print("Classification Report:\n", classification_report(y_test, y_pred_log))
log_cm = confusion_matrix(y_test, y_pred_log)
sns.heatmap(log_cm, annot=True, fmt='d', cmap='Blues')
plt.title("Logistic Regression Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# === LSTM Model ===
print("\n=== LSTM Model ===")
tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(X)
X_seq = tokenizer.texts_to_sequences(X)
X_pad = pad_sequences(X_seq, maxlen=300)

encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)

X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(X_pad, y_encoded, test_size=0.2, random_state=42)

lstm_model = Sequential()
lstm_model.add(Embedding(input_dim=5000, output_dim=64, input_length=300))
lstm_model.add(SpatialDropout1D(0.3))
lstm_model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))
lstm_model.add(Dense(1, activation='sigmoid'))

lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

history = lstm_model.fit(
    X_train_lstm, y_train_lstm,
    epochs=5, batch_size=64,
    validation_split=0.1,
    verbose=1
)

y_pred_lstm_proba = lstm_model.predict(X_test_lstm).ravel()
y_pred_lstm = (y_pred_lstm_proba > 0.5).astype(int)

# Evaluation
print(f"Accuracy: {accuracy_score(y_test_lstm, y_pred_lstm):.4f}")
print("Classification Report:\n", classification_report(y_test_lstm, y_pred_lstm))
lstm_cm = confusion_matrix(y_test_lstm, y_pred_lstm)
sns.heatmap(lstm_cm, annot=True, fmt='d', cmap='Greens')
plt.title("LSTM Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# === Accuracy and Loss Plot ===
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title('LSTM Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('LSTM Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.show()

# === ROC Curves ===
fpr_log, tpr_log, _ = roc_curve(y_test, log_probs)
fpr_lstm, tpr_lstm, _ = roc_curve(y_test_lstm, y_pred_lstm_proba)

plt.figure(figsize=(10, 6))
plt.plot(fpr_log, tpr_log, label=f"Logistic Regression (AUC = {auc(fpr_log, tpr_log):.2f})")
plt.plot(fpr_lstm, tpr_lstm, label=f"LSTM (AUC = {auc(fpr_lstm, tpr_lstm):.2f})")
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve Comparison")
plt.legend()
plt.grid(True)
plt.show()